{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec50ae7f",
   "metadata": {},
   "source": [
    "# Fire Detection Model Training\n",
    "This notebook trains a CNN model to detect fire in images and converts it to TensorFlow Lite for mobile deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519e4e3c",
   "metadata": {},
   "source": [
    "## 1. Setup and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d789042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install tensorflow\n",
    "!pip install pillow\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn\n",
    "!pip install opencv-python\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24b2fe9",
   "metadata": {},
   "source": [
    "## 2. Extract and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaecdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the dataset (assuming Firetrain.zip is uploaded to Colab)\n",
    "with zipfile.ZipFile('Firetrain.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('dataset')\n",
    "\n",
    "# Check dataset structure\n",
    "!ls -la dataset/\n",
    "print(\"\\nDataset structure:\")\n",
    "!find dataset/ -type d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cffb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images in each category\n",
    "fire_dir = 'dataset/fire_dataset/fire_images'\n",
    "non_fire_dir = 'dataset/fire_dataset/non_fire_images'\n",
    "\n",
    "fire_count = len(os.listdir(fire_dir))\n",
    "non_fire_count = len(os.listdir(non_fire_dir))\n",
    "\n",
    "print(f\"Fire images: {fire_count}\")\n",
    "print(f\"Non-fire images: {non_fire_count}\")\n",
    "print(f\"Total images: {fire_count + non_fire_count}\")\n",
    "print(f\"Fire ratio: {fire_count / (fire_count + non_fire_count) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2092824d",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e9da5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image parameters\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "\n",
    "def load_and_preprocess_image(image_path, label):\n",
    "    \"\"\"Load and preprocess a single image\"\"\"\n",
    "    try:\n",
    "        image = tf.io.read_file(image_path)\n",
    "        image = tf.image.decode_image(image, channels=3, expand_animations=False)\n",
    "        \n",
    "        # Ensure the image is 3D (height, width, channels)\n",
    "        if len(image.shape) > 3:\n",
    "            image = image[0]  # Take first frame if animated\n",
    "        \n",
    "        image.set_shape([None, None, 3])  # Set shape explicitly\n",
    "        image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "        image = tf.cast(image, tf.float32) / 255.0\n",
    "        return image, label\n",
    "    except:\n",
    "        # Return a black image if there's an error\n",
    "        image = tf.zeros([IMG_SIZE, IMG_SIZE, 3], dtype=tf.float32)\n",
    "        return image, label\n",
    "\n",
    "# Filter out problematic files first\n",
    "def is_valid_image(file_path):\n",
    "    \"\"\"Check if file is a valid static image\"\"\"\n",
    "    try:\n",
    "        with Image.open(file_path) as img:\n",
    "            return img.format in ['JPEG', 'PNG', 'JPG'] and not getattr(img, 'is_animated', False)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Create file paths and labels with filtering\n",
    "fire_files = [os.path.join(fire_dir, f) for f in os.listdir(fire_dir) \n",
    "              if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "non_fire_files = [os.path.join(non_fire_dir, f) for f in os.listdir(non_fire_dir) \n",
    "                  if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Filter out problematic images\n",
    "fire_files = [f for f in fire_files if is_valid_image(f)]\n",
    "non_fire_files = [f for f in non_fire_files if is_valid_image(f)]\n",
    "\n",
    "# Create labels (1 for fire, 0 for non-fire)\n",
    "fire_labels = [1] * len(fire_files)\n",
    "non_fire_labels = [0] * len(non_fire_files)\n",
    "\n",
    "all_files = fire_files + non_fire_files\n",
    "all_labels = fire_labels + non_fire_labels\n",
    "\n",
    "print(f\"Valid fire images: {len(fire_files)}\")\n",
    "print(f\"Valid non-fire images: {len(non_fire_files)}\")\n",
    "print(f\"Total valid files: {len(all_files)}\")\n",
    "print(f\"Total labels: {len(all_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be11329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "def show_sample_images(files, labels, class_names=['Non-Fire', 'Fire']):\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(15, 8))\n",
    "    \n",
    "    # Show fire images\n",
    "    fire_samples = [f for f, l in zip(files, labels) if l == 1][:4]\n",
    "    for i, img_path in enumerate(fire_samples):\n",
    "        img = Image.open(img_path)\n",
    "        axes[0, i].imshow(img)\n",
    "        axes[0, i].set_title('Fire')\n",
    "        axes[0, i].axis('off')\n",
    "    \n",
    "    # Show non-fire images\n",
    "    non_fire_samples = [f for f, l in zip(files, labels) if l == 0][:4]\n",
    "    for i, img_path in enumerate(non_fire_samples):\n",
    "        img = Image.open(img_path)\n",
    "        axes[1, i].imshow(img)\n",
    "        axes[1, i].set_title('Non-Fire')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_sample_images(all_files, all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b20565",
   "metadata": {},
   "source": [
    "## 4. Create TensorFlow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a290d0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "train_files, val_files, train_labels, val_labels = train_test_split(\n",
    "    all_files, all_labels, test_size=0.2, random_state=42, stratify=all_labels\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_files)}\")\n",
    "print(f\"Validation samples: {len(val_files)}\")\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_files, train_labels))\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((val_files, val_labels))\n",
    "\n",
    "# Apply preprocessing\n",
    "train_ds = train_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Add data augmentation for training\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.RandomBrightness(0.1),\n",
    "    layers.RandomContrast(0.1)\n",
    "])\n",
    "\n",
    "def augment_image(image, label):\n",
    "    return data_augmentation(image, training=True), label\n",
    "\n",
    "train_ds = train_ds.map(augment_image)\n",
    "\n",
    "# Batch and prefetch\n",
    "train_ds = train_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb08a08f",
   "metadata": {},
   "source": [
    "## 5. Create and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59eab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MobileNetV2-based model for mobile deployment\n",
    "def create_fire_detection_model():\n",
    "    # Use MobileNetV2 as base model (pre-trained on ImageNet)\n",
    "    base_model = keras.applications.MobileNetV2(\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Freeze base model initially\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Add custom classification head\n",
    "    model = keras.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_fire_detection_model()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddb8e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=3, factor=0.2)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b852f2a",
   "metadata": {},
   "source": [
    "## 6. Fine-tuning (Optional but Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b7f069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the base model for fine-tuning\n",
    "model.layers[0].trainable = True\n",
    "\n",
    "# Use a lower learning rate for fine-tuning\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-5),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Fine-tune for a few more epochs\n",
    "fine_tune_epochs = 10\n",
    "total_epochs = EPOCHS + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(\n",
    "    train_ds,\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=history.epoch[-1],\n",
    "    validation_data=val_ds,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2320273",
   "metadata": {},
   "source": [
    "## 7. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093a0ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_training_history(history, history_fine=None):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    ax1.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    \n",
    "    if history_fine:\n",
    "        ax1.plot(range(len(history.history['accuracy']), len(history.history['accuracy']) + len(history_fine.history['accuracy'])), \n",
    "                 history_fine.history['accuracy'], label='Fine-tune Train Accuracy')\n",
    "        ax1.plot(range(len(history.history['val_accuracy']), len(history.history['val_accuracy']) + len(history_fine.history['val_accuracy'])), \n",
    "                 history_fine.history['val_accuracy'], label='Fine-tune Val Accuracy')\n",
    "    \n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot loss\n",
    "    ax2.plot(history.history['loss'], label='Train Loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Val Loss')\n",
    "    \n",
    "    if history_fine:\n",
    "        ax2.plot(range(len(history.history['loss']), len(history.history['loss']) + len(history_fine.history['loss'])), \n",
    "                 history_fine.history['loss'], label='Fine-tune Train Loss')\n",
    "        ax2.plot(range(len(history.history['val_loss']), len(history.history['val_loss']) + len(history_fine.history['val_loss'])), \n",
    "                 history_fine.history['val_loss'], label='Fine-tune Val Loss')\n",
    "    \n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history, history_fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f731d092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "val_loss, val_accuracy = model.evaluate(val_ds, verbose=0)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Get predictions for confusion matrix\n",
    "y_pred = model.predict(val_ds)\n",
    "y_pred_classes = (y_pred > 0.5).astype(int).flatten()\n",
    "y_true = val_labels\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred_classes, target_names=['Non-Fire', 'Fire']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Fire', 'Fire'], yticklabels=['Non-Fire', 'Fire'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6efb25d",
   "metadata": {},
   "source": [
    "## 8. Convert to TensorFlow Lite for Mobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed7f475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert model to TensorFlow Lite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Optional: Apply optimizations for mobile deployment\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Convert the model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TensorFlow Lite model\n",
    "with open('fire_detection_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TensorFlow Lite model saved as 'fire_detection_model.tflite'\")\n",
    "print(f\"Model size: {len(tflite_model) / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6c9a30",
   "metadata": {},
   "source": [
    "## 9. Test the TensorFlow Lite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7860ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the TensorFlow Lite model\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(\"Input details:\")\n",
    "print(f\"  Name: {input_details[0]['name']}\")\n",
    "print(f\"  Shape: {input_details[0]['shape']}\")\n",
    "print(f\"  Type: {input_details[0]['dtype']}\")\n",
    "\n",
    "print(\"\\nOutput details:\")\n",
    "print(f\"  Name: {output_details[0]['name']}\")\n",
    "print(f\"  Shape: {output_details[0]['shape']}\")\n",
    "print(f\"  Type: {output_details[0]['dtype']}\")\n",
    "\n",
    "# Test with a sample image\n",
    "def test_tflite_model(image_path):\n",
    "    # Load and preprocess image\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img = img.resize((IMG_SIZE, IMG_SIZE))\n",
    "    img_array = np.array(img, dtype=np.float32) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Set input tensor\n",
    "    interpreter.set_tensor(input_details[0]['index'], img_array)\n",
    "    \n",
    "    # Run inference\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    # Get output\n",
    "    output = interpreter.get_tensor(output_details[0]['index'])\n",
    "    confidence = output[0][0]\n",
    "    \n",
    "    return confidence, \"Fire\" if confidence > 0.5 else \"No Fire\"\n",
    "\n",
    "# Test with sample images\n",
    "sample_images = val_files[:5]\n",
    "sample_labels = val_labels[:5]\n",
    "\n",
    "for i, (img_path, true_label) in enumerate(zip(sample_images, sample_labels)):\n",
    "    confidence, prediction = test_tflite_model(img_path)\n",
    "    true_class = \"Fire\" if true_label == 1 else \"No Fire\"\n",
    "    print(f\"Image {i+1}: True={true_class}, Predicted={prediction}, Confidence={confidence:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b35cd71",
   "metadata": {},
   "source": [
    "## 10. Save Model Files for Flutter Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51e560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Keras model as well (for future reference)\n",
    "model.save('fire_detection_model.h5')\n",
    "print(\"Keras model saved as 'fire_detection_model.h5'\")\n",
    "\n",
    "# Create a model info file\n",
    "model_info = {\n",
    "    'model_name': 'Fire Detection Model',\n",
    "    'input_shape': [1, IMG_SIZE, IMG_SIZE, 3],\n",
    "    'output_shape': [1, 1],\n",
    "    'input_type': 'float32',\n",
    "    'output_type': 'float32',\n",
    "    'classes': ['No Fire', 'Fire'],\n",
    "    'threshold': 0.5,\n",
    "    'preprocessing': 'Normalize to [0, 1] range',\n",
    "    'validation_accuracy': float(val_accuracy),\n",
    "    'model_size_mb': len(tflite_model) / 1024 / 1024\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('model_info.json', 'w') as f:\n",
    "    json.dump(model_info, f, indent=2)\n",
    "\n",
    "print(\"\\nModel information saved to 'model_info.json'\")\n",
    "print(json.dumps(model_info, indent=2))\n",
    "\n",
    "# List all files created\n",
    "print(\"\\nFiles created:\")\n",
    "!ls -la fire_detection_model.* model_info.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041334bf",
   "metadata": {},
   "source": [
    "## 11. Download Files\n",
    "\n",
    "**Download these files to use in your Flutter app:**\n",
    "\n",
    "1. **`fire_detection_model.tflite`** - The main model file for Flutter\n",
    "2. **`model_info.json`** - Model configuration and metadata\n",
    "3. **`fire_detection_model.h5`** - Full Keras model (for future training/improvements)\n",
    "\n",
    "**For Flutter integration, you'll need:**\n",
    "- Place `fire_detection_model.tflite` in `assets/models/` folder\n",
    "- Add the tflite_flutter package to pubspec.yaml\n",
    "- Use the model info for proper preprocessing in your app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0823cdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download files (uncomment the lines below in Google Colab)\n",
    "# from google.colab import files\n",
    "# files.download('fire_detection_model.tflite')\n",
    "# files.download('model_info.json')\n",
    "# files.download('fire_detection_model.h5')\n",
    "\n",
    "print(\"Training complete! ðŸ”¥\")\n",
    "print(f\"Final validation accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Model size: {len(tflite_model) / 1024 / 1024:.2f} MB\")\n",
    "print(\"\\nReady for Flutter integration!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
